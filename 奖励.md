王者荣耀-鲁班七号开发
奖励效果测试
原本设置

{ "reward_money": "0.008", "reward_exp": "0.008" , "reward_hp_point": "2.0", "reward_ep_rate": "0.75", "reward_kill": "-0.6", "reward_dead": "-1.0", "reward_tower_hp_point": "8.0", "reward_last_hit": "1.8", "log_level": "8" }

改进奖励打法
{ "reward_money": "0.02", "reward_exp": "0.002" , "reward_hp_point": "2.0", "reward_ep_rate": "0.8", "reward_kill": "-0.5", "reward_dead": "-1.0", "reward_tower_hp_point": "10.0", "reward_last_hit": "0.5", "log_level": "8" }

训练一小时的情况
-不推塔
-推塔抗伤害
-死了一次后变笨，原地开枪过了很久才开始打兵线
-无端端闪现
-红开就变笨蛋，过了很久才清线
-可能是探索值太低

建议：
你的AI在训练过程中表现出的行为可能是由于多种因素导致的。以下是一些可能的解决方案：

探索值：你提到可能是探索值太低。在强化学习中，探索值（或称为epsilon）是一个重要的参数，它决定了AI在学习过程中是选择已知的最优策略（贪婪）还是尝试新的策略（探索）。如果探索值太低，AI可能会过于依赖已知的策略，而不去尝试可能更优的策略。你可以尝试提高探索值，让AI有更多的机会去探索新的策略。

奖励函数：奖励函数是强化学习的关键部分，它决定了AI的行为。你可以尝试调整奖励函数的参数，以鼓励AI进行更优的行为。例如，你可以增加推塔的奖励（reward_tower_hp_point），或者减少死亡的惩罚（reward_dead），以鼓励AI更积极地推塔。

学习率：学习率（learning_rate）决定了AI在每次更新时对新信息的接受程度。如果学习率太低，AI可能需要更长的时间才能学习到有效的策略。你可以尝试提高学习率，让AI更快地学习新的策略。

训练时间：强化学习通常需要大量的时间和样本才能学习到有效的策略。你提到你的AI只训练了一小时，这可能是不够的。你可以尝试让AI训练更长的时间，看看是否能改善其表现。

请注意，以上的建议可能需要反复试验和调整才能找到最优的设置。祝你好运！

再次更改
提高死亡带来的reward
{
“reward_money”: “0.002”, ->需要减小
“reward_exp”: “0.002” , ->需要减小
“reward_hp_point”: “2.0”,
“reward_ep_rate”: “0.8”,
“reward_kill”: “-0.45”,
“reward_dead”: “-0.9”, ->需要增大
“reward_tower_hp_point”: “10.0”, ->需要减小
“reward_last_hit”: “0.5”,
“log_level”: “8”
}
提升学习率
learning_rate = 0.0002
训练12小时试试看

进展
-会开始清兵线->reward money 和 reward exp达到平衡
-学习效率提升显着带来效果->今晚可以尝试更高
-迷惑行为减少

未解决
-血量过少不回城补血
-推塔的值过高，导致比起死亡也要去推塔
-技能乱用的情况

总结：因为不了解平台机制，我们误在再训练时使用了调错的参数，所以造成我们只能够使用24小时的模型，然后漏掉的细节就是可以使用分而治之的思路来训练模型。